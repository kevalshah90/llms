{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0a52f9-4e5c-4ba2-b4ef-91f4bbfa939e",
   "metadata": {},
   "source": [
    "### RL Deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f5b5f-b666-4fbe-a853-89da53a6f2f8",
   "metadata": {},
   "source": [
    "Intro:\n",
    "\n",
    "Language models have shown impressive capabilities in the past few years by generating diverse and compelling text from human input prompts. However, what makes a \"good\" text is inherently hard to define as it is subjective and context dependent. There are many applications such as writing stories where you want creativity, pieces of informative text which should be truthful, or code snippets that we want to be executable.\n",
    "\n",
    "Writing a loss function to capture these attributes seems intractable and most language models are still trained with a simple next token prediction loss (e.g. cross entropy). \n",
    "\n",
    "Large Language Models, such as GPT and BERT, are trained using the cross-entropy loss function. During training, these models predict the probability distribution over a vocabulary for the next word or token in a sequence. The cross-entropy loss measures the difference between this predicted distribution and the actual next word. Minimizing this loss helps the model improve its predictions over time. For instance, when an LLM predicts the next word in a sentence, it generates a probability distribution across all possible words in its vocabulary. The cross-entropy loss then quantifies how far this predicted distribution is from the actual next word, guiding the model to adjust its parameters to make more accurate predictions in future iterations.\n",
    "\n",
    "In pytorch, `torch.nn.CrossEntropyLoss` combines `LogSoftmax` which converts output logits to log probabilities and `Negative Log-Likelihood Loss`, \n",
    "\n",
    "Given a dataset with N observations, and a model that assigns a probability `p(y_i | x_i; \\theta)` to each observation `(x_i, y_i)` based on parameters `\\theta`, the NLL is defined as:\n",
    "\n",
    "`\\text{NLL}(\\theta) = -\\sum_{i=1}^{N} \\log p(y_i | x_i; \\theta)`\n",
    "\n",
    "Here, `p(y_i | x_i; \\theta)` represents the probability assigned by the model to the true outcome `y_i` given input `x_i` and parameters `\\theta`. Minimizing the NLL is equivalent to maximizing the likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34977a0-e291-420b-a1e3-f3e03857e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Sample logits tensor of shape (batch_size=2, sequence_length=3, vocab_size=5)\n",
    "# logits = torch.tensor([[[2.0, 1.0, 0.1, 0.5, 0.3],\n",
    "#                         [0.2, 1.5, 0.3, 0.7, 0.8],\n",
    "#                         [1.0, 0.2, 0.8, 0.5, 1.2]],\n",
    "\n",
    "#                        [[0.5, 1.0, 1.5, 0.2, 0.3],\n",
    "#                         [1.2, 0.7, 0.5, 1.0, 0.9],\n",
    "#                         [0.3, 0.8, 1.0, 1.5, 0.4]]])\n",
    "\n",
    "# # Corresponding target tensor of shape (batch_size=2, sequence_length=3)\n",
    "# targets = torch.tensor([[0, 3, 4],\n",
    "#                         [2, 1, 3]])\n",
    "\n",
    "# # Initialize the CrossEntropyLoss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Compute the loss for each position in the sequence\n",
    "# loss = criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8ea8a-1d3b-49b4-879c-8bbe98fba39c",
   "metadata": {},
   "source": [
    "To compensate for the shortcomings of the loss itself people define metrics that are designed to better capture human preferences such as BLEU or ROUGE. While being better suited than the loss function itself at measuring performance these metrics simply compare generated text to references with simple rules and are thus also limited. Wouldn't it be great if we use human feedback for generated text as a measure of performance or go even one step further and use that feedback as a loss to optimize the model? That's the idea of Reinforcement Learning from Human Feedback (RLHF); use methods from reinforcement learning to directly optimize a language model with human feedback. RLHF has enabled language models to begin to align a model trained on a general corpus of text data to that of complex human values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61826850-e13c-4cf5-9602-c4ce6e96a858",
   "metadata": {},
   "source": [
    "**Reinforcement learning from Human Feedback (also referenced as RL from human preferences) is a challenging concept because it involves a multiple-model training process and different stages of deployment.**\n",
    "\n",
    "1. Pretraining a language model (LM)\n",
    "   \n",
    "2. gathering data and training a reward model, and\n",
    "\n",
    "3. Fine-tuning the LM with reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efa4e1-051a-45be-ad8a-d9c90796c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf94c1-406e-4067-8174-dd709e6d18db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a70f2-cd74-4ec8-8212-8fa1006248f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b0015-a0ba-447a-9ccc-de655ace0566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8c095-5b10-44f7-9b03-a7dcc381012c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e6f5c-3e9e-424e-a04a-bb4360c6bc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50843e79-d122-4f77-9ca5-5e8199fd04dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3371c3-0ab6-4934-926e-52c902696b25",
   "metadata": {},
   "source": [
    "References, \n",
    "\n",
    "- https://huggingface.co/blog/rlhf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
