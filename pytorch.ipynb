{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevalshah90/llms/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UfB6stujgXKe",
        "outputId": "443b0289-b47a-499b-e34d-9c4bcf1b4ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/gpu')"
      ],
      "metadata": {
        "id": "y-TiJ8WcgcTp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gpu/')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "62VCQ5sUgeIZ",
        "outputId": "b16b77cd-30ac-441d-9189-221e7a557437"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "yZ4Fsg98gljA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "!sudo apt install graphviz"
      ],
      "metadata": {
        "id": "64lviLRRf8_2",
        "outputId": "8ec96113-89c8-4d01-db11-b29c6efa13ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4x6OtHJ47s",
        "outputId": "08a2d6aa-06a6-4b7a-d7db-5ed9f7fa94ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Creating Tensors**"
      ],
      "metadata": {
        "id": "0_YFG5PRhALJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor shapes are represented as (row, column)"
      ],
      "metadata": {
        "id": "bFRXayWzmZyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty tensor (uninitialized values)\n",
        "x = torch.empty(2,3)\n",
        "print(\"Empty:\\n\", x)\n",
        "print(\"Shape\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWFm-2MfguVp",
        "outputId": "e981fbf3-861c-4995-9438-307f92642239"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty:\n",
            " tensor([[3.4822e-34, 0.0000e+00, 1.5526e-42],\n",
            "        [4.5572e-41, 3.4822e-34, 0.0000e+00]])\n",
            "Shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor of zeros\n",
        "zeros = torch.zeros(2, 3)\n",
        "print(\"Zeros:\\n\", zeros)\n",
        "print(\"Shape\", zeros.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzkOwABhPNF",
        "outputId": "62a67f0d-6641-453f-ad56-791b1f1812a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor of ones\n",
        "ones = torch.ones(2, 3)\n",
        "print(\"Ones:\\n\", ones)\n",
        "print(\"Shape\", ones.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UanCqYyThSdc",
        "outputId": "3cad538c-bca4-4787-8d5a-6cc69c4359a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random tensor\n",
        "rand = torch.rand(2, 3)\n",
        "print(\"Random:\\n\", rand)\n",
        "print(\"Shape\", rand.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uMXvNYmhZr1",
        "outputId": "4f9fad7e-ff4a-4bbc-dbe2-6aec1d8e1cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random:\n",
            " tensor([[0.6682, 0.7786, 0.7509],\n",
            "        [0.4421, 0.8565, 0.4874]])\n",
            "Shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor from data\n",
        "data = torch.tensor([[1, 2], [3, 4]])\n",
        "print(\"From data:\\n\", data)\n",
        "print(\"Shape\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvmJ2dIXhqjx",
        "outputId": "79e76a5b-e0cf-48d4-c854-05d580663ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From data:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Shape torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor from numpy\n",
        "np_array = np.array([[1, 2], [3, 4]])\n",
        "from_numpy = torch.from_numpy(np_array)\n",
        "print(\"From numpy:\\n\", from_numpy)\n",
        "print(\"Shape\", from_numpy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfY247_Rh277",
        "outputId": "f836b8e0-386c-4775-ce6a-d445b8764ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From numpy:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Shape torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Manipulations / Basic Operations / Reshaping**"
      ],
      "metadata": {
        "id": "HSU2QnAiiXdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "print(\"Shape a, b:\", a.shape, b.shape)\n",
        "\n",
        "# Addition\n",
        "print(\"Addition:\", a + b)\n",
        "\n",
        "# Subtraction\n",
        "print(\"Subtraction:\", a - b)\n",
        "\n",
        "# Multiplication\n",
        "print(\"Multiplication:\", a * b)\n",
        "\n",
        "# Division\n",
        "print(\"Division:\", a / b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe99_NgoiEWU",
        "outputId": "4409cd09-2ae9-4221-ff5d-4fbd46f45f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape a, b: torch.Size([3]) torch.Size([3])\n",
            "Addition: tensor([5, 7, 9])\n",
            "Subtraction: tensor([-3, -3, -3])\n",
            "Multiplication: tensor([ 4, 10, 18])\n",
            "Division: tensor([0.2500, 0.4000, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "# Matrix multiplication\n",
        "C = torch.mm(A, B)\n",
        "print(\"Matrix Multiplication (mm):\\n\", C)\n",
        "\n",
        "# Using @ operator\n",
        "C2 = A @ B\n",
        "print(\"Matrix Multiplication (@):\\n\", C2)\n",
        "\n",
        "# Using matmul\n",
        "C3 = torch.matmul(A, B)\n",
        "print(\"Matrix Multiplication (matmul):\\n\", C3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Daqpg0XKidGc",
        "outputId": "5a0d1085-043c-4af7-e003-73837212dea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication (mm):\n",
            " tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "Matrix Multiplication (@):\n",
            " tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "Matrix Multiplication (matmul):\n",
            " tensor([[19., 22.],\n",
            "        [43., 50.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "x = torch.arange(12)\n",
        "print(\"Original:\\n\", x)\n",
        "print(\"Shape:\", x.shape)\n",
        "reshaped = x.view(3, 4)\n",
        "print(\"Reshaped:\\n\", reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltx14vVJiuEH",
        "outputId": "d6898137-3fff-436c-c66c-d4d3915d3a98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
            "Shape: torch.Size([12])\n",
            "Reshaped:\n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [1,2,3,4,5,6,7,8]\n",
        "x = torch.tensor(data)             # Shape: (8,)\n",
        "print(\"Original data:\", x)\n",
        "print(\"Original Shape:\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSqI9hQPjP15",
        "outputId": "ca9068c9-aadc-40a9-95d5-e5a20374081e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "Original Shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(2, 4)                       # Shape: (2, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yjPY1XdmSIq",
        "outputId": "f7047d3d-7a96-4811-ca99-b3c7343eb3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4],\n",
              "        [5, 6, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.reshape(2, 4)                # Shape: (2, 4)\n",
        "print(\"Reshaped data:\\n\", y)\n",
        "print(\"Reshaped Shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRnL-u9UjqD6",
        "outputId": "3d3a0c48-a586-4c42-d293-c671a6680c62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped data:\n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "Reshaped Shape: torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x.reshape(2, 2, 2)             # Shape: (2, 2, 2)\n",
        "print(\"Reshaped data:\\n\", z)\n",
        "print(\"Reshaped Shape:\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7VEGoE1jigL",
        "outputId": "24798a33-d447-4b22-8b30-0772f5abc7a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped data:\n",
            " tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "Reshaped Shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsqueeze\n",
        "# Adds a dimension of size 1 at the specified position (axis)\n",
        "# useful for adding batch or channel dimensions.\n",
        "\n",
        "x = torch.tensor([1, 2, 3, 4])     # Shape: (4,)\n",
        "print(\"Original data:\\n\", x)\n",
        "print(\"Original Shape:\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRyihe17nPHS",
        "outputId": "98ed7194-02bc-4e8d-ac9b-9fc6994f5ddd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            " tensor([1, 2, 3, 4])\n",
            "Original Shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new dimension at position 0 (front)\n",
        "y = torch.unsqueeze(x, 0)          # Shape: (1, 4)\n",
        "print(\"Unsqueezed data:\\n\", y)\n",
        "print(\"Unsqueezed Shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUWYooC6nhpM",
        "outputId": "e0cfc513-58f0-440f-82be-fbac39105fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsqueezed data:\n",
            " tensor([[1, 2, 3, 4]])\n",
            "Unsqueezed Shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new dimension at position 1 (end)\n",
        "z = torch.unsqueeze(x, 1)          # Shape: (4, 1)\n",
        "print(\"Unsqueezed data:\\n\", z)\n",
        "print(\"Unsqueezed Shape:\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtM0wAZ0nf1Q",
        "outputId": "5cbee547-3139-4fe6-9f41-f1606bfc5a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsqueezed data:\n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "Unsqueezed Shape: torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Squeeze\n",
        "# Removes dimensions of size 1.\n",
        "# If a specific dimension is given, only squeezes that dimension if its size is 1.\n",
        "\n",
        "x = torch.ones(2, 1, 2)            # Shape: (2, 1, 2)\n",
        "print(\"Original data:\\n\", x)\n",
        "print(\"Original Shape:\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PSfcEeDoSod",
        "outputId": "dfcdcb32-cf72-4ea2-d450-7c519b00378a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            " tensor([[[1., 1.]],\n",
            "\n",
            "        [[1., 1.]]])\n",
            "Original Shape: torch.Size([2, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.squeeze(x, dim=1)               # Shape: (2, 2)\n",
        "print(\"Squeezed data:\\n\", y)\n",
        "print(\"Squeezed Shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAg4wPGcodV7",
        "outputId": "f5c72479-7dc4-42b9-c8ad-0e50dde3de98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squeezed data:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "Squeezed Shape: torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.squeeze(x, 1)            # Shape: (2, 2)\n",
        "print(\"Squeezed data:\\n\", z)\n",
        "print(\"Squeezed Shape:\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bMm65zDol1C",
        "outputId": "c718c425-7fb2-4b5a-ebbb-d2e37cdb8ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squeezed data:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "Squeezed Shape: torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Autograd**\n",
        "\n",
        ". Autograd: Automatic Differentiation & Computation Graphs\n",
        "PyTorch’s `autograd` is an engine that automatically computes gradients for tensor operations, enabling efficient backpropagation for neural network training.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "\t•\tComputation Graph:\n",
        "Every operation on tensors with `requires_grad=True` is recorded in a dynamic computation graph. This graph tracks how each tensor is derived from others, allowing PyTorch to compute derivatives using the chain rule.\n",
        "\n",
        "\t•\tAutomatic Differentiation:\n",
        "When you call `.backward()` on a scalar output (like a loss), autograd traverses the computation graph from output to input, computing gradients for all tensors that have `requires_grad=True`"
      ],
      "metadata": {
        "id": "5ysQn0BAp8kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5)  # Input tensor\n",
        "y = torch.zeros(3) # Target tensor\n",
        "w = torch.randn(5, 3, requires_grad=True)  # Weights (parameters)\n",
        "b = torch.randn(3, requires_grad=True)     # Bias (parameters)\n",
        "\n",
        "print(\"Inputs:\", x)\n",
        "print(\"Inputs Shape:\", x.shape)\n",
        "\n",
        "print(\"Targets:\", y)\n",
        "print(\"Targets Shape:\", y.shape)\n",
        "\n",
        "print(\"Weights:\", w)\n",
        "print(\"Weights Shape:\", w.shape)\n",
        "\n",
        "print(\"Biases:\", b)\n",
        "print(\"Biases Shape:\", b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KOnO8L_p8DO",
        "outputId": "e2de329c-93fa-4afb-e88f-7c367da26c68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([1., 1., 1., 1., 1.])\n",
            "Inputs Shape: torch.Size([5])\n",
            "Targets: tensor([0., 0., 0.])\n",
            "Targets Shape: torch.Size([3])\n",
            "Weights: tensor([[-0.0295,  0.8848, -0.5108],\n",
            "        [ 2.2497,  2.3181, -0.7023],\n",
            "        [-0.3785, -1.5514,  0.0183],\n",
            "        [-1.1340,  1.0937,  0.0170],\n",
            "        [ 0.7008, -0.7555,  1.3509]], requires_grad=True)\n",
            "Weights Shape: torch.Size([5, 3])\n",
            "Biases: tensor([-0.4831, -0.8344,  0.3304], requires_grad=True)\n",
            "Biases Shape: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w) + b\n",
        "print(\"z:\", z)\n",
        "print(\"z Shape:\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Fh7HFYqhed",
        "outputId": "022b0177-7cfd-4084-e23d-8afb14f2c7fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z: tensor([0.9254, 1.1552, 0.5035], grad_fn=<AddBackward0>)\n",
            "z Shape: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute loss\n",
        "# BCE: loss function for binary classification tasks, quantifies the difference between predicted probabilities and true binary labels (0 or 1),\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "print(\"grad_fn for loss:\", loss.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uTAGDcxr5xA",
        "outputId": "f00d7c5e-2e35-4cb1-cb2f-d9ddd9ef117a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad_fn for loss: <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f09a8a83b50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()  # Computes gradients for w and b\n",
        "print(\"Weight gradient:\\n\", w.grad)    # Gradient of loss w.r.t. w\n",
        "print(\"Bias gradient:\\n\", b.grad)    # Gradient of loss w.r.t. b"
      ],
      "metadata": {
        "id": "h1V218rSflKI",
        "outputId": "f80a7938-56ae-421d-fb05-819c144f03d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight gradient:\n",
            " tensor([[0.2387, 0.2535, 0.2078],\n",
            "        [0.2387, 0.2535, 0.2078],\n",
            "        [0.2387, 0.2535, 0.2078],\n",
            "        [0.2387, 0.2535, 0.2078],\n",
            "        [0.2387, 0.2535, 0.2078]])\n",
            "Bias gradient:\n",
            " tensor([0.2387, 0.2535, 0.2078])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the graph with parameters labeled\n",
        "dot = make_dot(loss, params={'w': w, 'b': b})\n",
        "# Display inline\n",
        "dot\n",
        "\n",
        "#dot.format = \"png\"\n",
        "#dot.render(\"bce_autograd_graph\", cleanup=True)\n",
        "\n",
        "#print(\"Graph saved as bce_autograd_graph.png\")"
      ],
      "metadata": {
        "id": "Fj9rpAXugYko",
        "outputId": "0d09abee-2090-4c4b-d0dc-1c9949c404cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"247pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 247.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 243,-387 243,4 -4,4\"/>\n<!-- 139679460552112 -->\n<g id=\"node1\" class=\"node\">\n<title>139679460552112</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"146.5,-31 92.5,-31 92.5,0 146.5,0 146.5,-31\"/>\n<text text-anchor=\"middle\" x=\"119.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139683683873648 -->\n<g id=\"node2\" class=\"node\">\n<title>139683683873648</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"239,-86 0,-86 0,-67 239,-67 239,-86\"/>\n<text text-anchor=\"middle\" x=\"119.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">BinaryCrossEntropyWithLogitsBackward0</text>\n</g>\n<!-- 139683683873648&#45;&gt;139679460552112 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139683683873648&#45;&gt;139679460552112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M119.5,-66.79C119.5,-60.07 119.5,-50.4 119.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"123,-41.19 119.5,-31.19 116,-41.19 123,-41.19\"/>\n</g>\n<!-- 139683683866304 -->\n<g id=\"node3\" class=\"node\">\n<title>139683683866304</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"164,-141 75,-141 75,-122 164,-122 164,-141\"/>\n<text text-anchor=\"middle\" x=\"119.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 139683683866304&#45;&gt;139683683873648 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139683683866304&#45;&gt;139683683873648</title>\n<path fill=\"none\" stroke=\"black\" d=\"M119.5,-121.75C119.5,-114.8 119.5,-104.85 119.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"123,-96.09 119.5,-86.09 116,-96.09 123,-96.09\"/>\n</g>\n<!-- 139683683866160 -->\n<g id=\"node4\" class=\"node\">\n<title>139683683866160</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-196 1,-196 1,-177 114,-177 114,-196\"/>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SqueezeBackward4</text>\n</g>\n<!-- 139683683866160&#45;&gt;139683683866304 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139683683866160&#45;&gt;139683683866304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.46,-176.98C76.63,-169.15 90.44,-157.34 101.53,-147.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"104.03,-150.33 109.36,-141.17 99.48,-145.01 104.03,-150.33\"/>\n</g>\n<!-- 139683683866352 -->\n<g id=\"node5\" class=\"node\">\n<title>139683683866352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"99,-256.5 16,-256.5 16,-237.5 99,-237.5 99,-256.5\"/>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 139683683866352&#45;&gt;139683683866160 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139683683866352&#45;&gt;139683683866160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M57.5,-237.37C57.5,-229.25 57.5,-216.81 57.5,-206.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61,-206.17 57.5,-196.17 54,-206.17 61,-206.17\"/>\n</g>\n<!-- 139683683863520 -->\n<g id=\"node6\" class=\"node\">\n<title>139683683863520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"108,-317 7,-317 7,-298 108,-298 108,-317\"/>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139683683863520&#45;&gt;139683683866352 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139683683863520&#45;&gt;139683683866352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M57.5,-297.87C57.5,-289.75 57.5,-277.31 57.5,-266.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61,-266.67 57.5,-256.67 54,-266.67 61,-266.67\"/>\n</g>\n<!-- 139679460554416 -->\n<g id=\"node7\" class=\"node\">\n<title>139679460554416</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"87,-383 28,-383 28,-353 87,-353 87,-383\"/>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">w</text>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (5, 3)</text>\n</g>\n<!-- 139679460554416&#45;&gt;139683683863520 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139679460554416&#45;&gt;139683683863520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M57.5,-352.84C57.5,-345.21 57.5,-335.7 57.5,-327.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61,-327.27 57.5,-317.27 54,-327.27 61,-327.27\"/>\n</g>\n<!-- 139683683866400 -->\n<g id=\"node8\" class=\"node\">\n<title>139683683866400</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"233,-196 132,-196 132,-177 233,-177 233,-196\"/>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139683683866400&#45;&gt;139683683866304 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139683683866400&#45;&gt;139683683866304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.38,-176.98C163.06,-169.15 149.03,-157.34 137.76,-147.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.71,-144.93 129.81,-141.17 135.21,-150.29 139.71,-144.93\"/>\n</g>\n<!-- 139679449509872 -->\n<g id=\"node9\" class=\"node\">\n<title>139679449509872</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"209.5,-262 155.5,-262 155.5,-232 209.5,-232 209.5,-262\"/>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">b</text>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 139679449509872&#45;&gt;139683683866400 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139679449509872&#45;&gt;139683683866400</title>\n<path fill=\"none\" stroke=\"black\" d=\"M182.5,-231.84C182.5,-224.21 182.5,-214.7 182.5,-206.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186,-206.27 182.5,-196.27 179,-206.27 186,-206.27\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f098fcf1690>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Simple Neural Network**"
      ],
      "metadata": {
        "id": "woQbHPpNsIgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() #\n",
        "        self.fc1 = nn.Linear(4, 3)  # First linear layer\n",
        "        self.relu = nn.ReLU()       # Activation\n",
        "        self.fc2 = nn.Linear(3, 1)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "print(\"model:\\n\", model)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvMfB5posHxE",
        "outputId": "e63ec668-c941-4b2c-b145-f4e102fd7447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:\n",
            " SimpleNet(\n",
            "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "fc1.weight torch.Size([3, 4])\n",
            "fc1.bias torch.Size([3])\n",
            "fc2.weight torch.Size([1, 3])\n",
            "fc2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`nn.CrossEntropyLoss`**. This loss function is specifically designed for multi-class classification tasks where the goal is to predict the next token (word, subword, or character) from a vocabulary, which is the core objective in language modeling.\n",
        "\n",
        "`CrossEntropyLoss`?\n",
        "\n",
        "\t•\tLanguage modeling is a multi-class classification problem: for each position in the sequence, the model predicts one token out of the entire vocabulary.\n",
        "\n",
        "\t•\t`nn.CrossEntropyLoss` combines `log_softmax` and negative log-likelihood loss in a single, numerically stable function.\n",
        "  \n",
        "\t•\tThe model’s output (logits) should have shape `batch_size, vocab_size` for each time step, and the target should be the index of the correct next token."
      ],
      "metadata": {
        "id": "6aJ6XTmNtrnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose output is [batch_size, vocab_size] and target is [batch_size]\n",
        "output = torch.randn(32, 10000)  # logits for 32 samples, 10,000 vocab size\n",
        "print(\"Output:\\n\", output)\n",
        "print(\"Output Shape:\", output.shape)\n",
        "\n",
        "target = torch.randint(0, 10000, (32,))  # target token indices\n",
        "print(\"Target:\\n\", target)\n",
        "print(\"Target Shape:\", target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDaxDkwStmMy",
        "outputId": "9b2f55cf-1c7f-4a1f-8893-dee7bf8840cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            " tensor([[-1.1844,  0.2629, -0.4970,  ..., -0.6772, -1.5638,  0.1890],\n",
            "        [-0.8921, -0.2371,  0.1527,  ..., -0.6550,  0.0168,  0.6555],\n",
            "        [ 0.2130, -1.4675, -1.2612,  ..., -0.5177, -0.3987, -0.2560],\n",
            "        ...,\n",
            "        [-0.0385, -1.6277,  0.8579,  ..., -1.2634,  0.1796,  0.6680],\n",
            "        [ 0.1526,  0.8426, -1.1346,  ..., -0.3724,  0.2880, -1.0769],\n",
            "        [ 0.1524,  1.1086,  0.0130,  ...,  2.1940,  1.7321, -0.4754]])\n",
            "Output Shape: torch.Size([32, 10000])\n",
            "Target:\n",
            " tensor([3363, 1050, 5131, 2486, 1400,  780, 4004, 1910,  472, 8286, 9509, 5565,\n",
            "        3092, 4865, 8314,  249,   75, 9517, 3555, 8755, 8743, 9219, 9869, 6650,\n",
            "        9243, 8029,  279, 7038, 4883, 9049, 5751, 8804])\n",
            "Target Shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(output, target)\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFKWPY03t5pK",
        "outputId": "a6635e14-008f-4a60-943e-020fc3f47fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(9.7297)\n"
          ]
        }
      ]
    }
  ]
}